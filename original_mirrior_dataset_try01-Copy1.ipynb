{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trying to make new file with combination of old images dataset and its mirror one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def making_array_of_original_mirror_images(fileName):\n",
    "#    data=pd.read_csv(fileName)\n",
    "#    emoation, pixels = data['']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimentions  (999, 3)\n",
      "types \n",
      " emotion     int64\n",
      "pixels     object\n",
      "Usage      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('sample1000.csv')\n",
    "print(\"dimentions \", data.shape)\n",
    "print(\"types \\n\",data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "35887*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training    999\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Usage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotions , data_pixels = data['emotion'] , data['pixels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_length = len(emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_pixels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-92610fe8e0d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m                         })\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maugmented_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0maugmented_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fer2013_v02.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m#augmented_dataset.to_csv(\"fer2013_augmented.csv\",index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-92610fe8e0d8>\u001b[0m in \u001b[0;36mdata_augment\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimage_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0memotion_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def data_augment(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    emotions , data_pixels = data['emotion'] , data['pixels']\n",
    "    total_length = len(emotions)\n",
    "    data_pixel_df = np.array([])\n",
    "    emotion_list = np.array([])\n",
    "    image_list = np.array([])\n",
    "    for i in range(total_length):\n",
    "        emotion_list.append(emotions[i])\n",
    "         \n",
    "    \n",
    "        for line in data_pixels[i].split(\" \"):\n",
    "            data_pixel_df.append(float(line))\n",
    "            \n",
    "        \n",
    "        data_pixel_df_array = np.array(data_pixel_df)\n",
    "        original_image = \" \".join(str(a) for a in data_pixel_df_array)\n",
    "        image_list = np.append(image_list,original_image)\n",
    "        \n",
    "        data_pixel_df_array = data_pixel_df_array.reshape(48,48)\n",
    "        flip_image = cv2.flip(data_pixel_df_array,1)\n",
    "        #rotate image\n",
    "        image_center = tuple(np.array(data_pixel_df_array.shape)/2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(image_center,10,1.0)\n",
    "        rotated_image = cv2.warpAffine(data_pixel_df_array,rotation_matrix,data_pixel_df_array.shape)\n",
    "    \n",
    "        #ab=flip_image\n",
    "        ab = flip_image.reshape(2304,)\n",
    "        flip_image_in_str = \" \".join(str(a) for a in ab)\n",
    "        emotion_list.append(emotions[i])\n",
    "        image_list.append(flip_image_in_str)\n",
    "        #cd=rotated_image\n",
    "        cd = rotated_image.reshape(2304,)\n",
    "        rotated_image_in_str = \" \".join(str(c) for c in cd)\n",
    "        emotion_list.append(emotions[i])\n",
    "        image_list.append(rotated_image_in_str)\n",
    "        data_pixel_df=[]\n",
    "    augmented_dataframe = pd.DataFrame({\n",
    "                        'emotion': emotion_list,\n",
    "                        'pixels' : image_list\n",
    "                        })\n",
    "    return augmented_dataframe\n",
    "augmented_dataset = data_augment(\"fer2013_v02.csv\")\n",
    "#augmented_dataset.to_csv(\"fer2013_augmented.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_augment(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    emotions , data_pixels = data['emotion'] , data['pixels']\n",
    "    total_length = len(emotions)\n",
    "    data_pixel_df = []\n",
    "    emotion_list = []\n",
    "    image_list = []\n",
    "    for i in range(total_length):\n",
    "        emotion_list.append(emotions[i])\n",
    "         \n",
    "    \n",
    "        for line in data_pixels[i].split(\" \"):\n",
    "            data_pixel_df.append(float(line))\n",
    "            \n",
    "        \n",
    "        data_pixel_df_array = np.array(data_pixel_df)\n",
    "        original_image = \" \".join(str(int(a)) for a in data_pixel_df_array)\n",
    "        image_list.append(original_image)\n",
    "        \n",
    "        data_pixel_df_array = data_pixel_df_array.reshape(48,48)\n",
    "        flip_image = cv2.flip(data_pixel_df_array,1)\n",
    "        #rotate image\n",
    "        image_center = tuple(np.array(data_pixel_df_array.shape)/2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(image_center,10,1.0)\n",
    "        rotated_image = cv2.warpAffine(data_pixel_df_array,rotation_matrix,data_pixel_df_array.shape)\n",
    "    \n",
    "        #ab=flip_image\n",
    "        ab = flip_image.reshape(2304,)\n",
    "        flip_image_in_str = \" \".join(str(int(a)) for a in ab)\n",
    "        emotion_list.append(emotions[i])\n",
    "        image_list.append(flip_image_in_str)\n",
    "        #cd=rotated_image\n",
    "        cd = rotated_image.reshape(2304,)\n",
    "        rotated_image_in_str = \" \".join(str(int(c)) for c in cd)\n",
    "        emotion_list.append(emotions[i])\n",
    "        image_list.append(rotated_image_in_str)\n",
    "        data_pixel_df=[]\n",
    "    augmented_dataframe = pd.DataFrame({\n",
    "                        'emotion': emotion_list,\n",
    "                        'pixels' : image_list\n",
    "                        })\n",
    "    return augmented_dataframe\n",
    "augmented_dataset = data_augment(\"/home/rahul/project/facial-expression-work/datasets/trainDataSet_v01.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmented_dataset.to_csv(\"/home/rahul/project/facial-expression-work/datasets/train_augMent_v02.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>153 147 127 98 118 142 144 147 158 167 177 178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>149 150 117 91 94 103 114 124 134 145 153 166 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 31 63 102 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>249 248 247 247 247 247 246 245 245 244 242 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>168 179 142 127 88 137 116 103 79 38 66 59 61 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 17 29 31 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>175 134 29 43 43 43 42 44 43 42 43 44 44 43 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>255 218 195 222 200 49 43 48 49 47 47 45 46 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 16 24 32 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>141 255 255 102 0 0 167 255 255 70 0 0 199 255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>152 0 0 111 254 255 141 9 2 1 0 12 24 37 7 69 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 26 63 107 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion                                             pixels\n",
       "0         6  153 147 127 98 118 142 144 147 158 167 177 178...\n",
       "1         6  149 150 117 91 94 103 114 124 134 145 153 166 ...\n",
       "2         6  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 31 63 102 13...\n",
       "3         0  249 248 247 247 247 247 246 245 245 244 242 25...\n",
       "4         0  168 179 142 127 88 137 116 103 79 38 66 59 61 ...\n",
       "5         0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 17 29 31 3...\n",
       "6         5  175 134 29 43 43 43 42 44 43 42 43 44 44 43 49...\n",
       "7         5  255 218 195 222 200 49 43 48 49 47 47 45 46 48...\n",
       "8         5  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 16 24 32 4...\n",
       "9         4  141 255 255 102 0 0 167 255 255 70 0 0 199 255...\n",
       "10        4  152 0 0 111 254 255 141 9 2 1 0 12 24 37 7 69 ...\n",
       "11        4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 26 63 107 14..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_dataset[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flip_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flip_image.reshape(2304,).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#flip_image_in_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#image_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(flip_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "48*48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array_1 = np.array([1,5,5,6,8,9,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(array_1.shape)\n",
    "array_1.reshape(3,3)\n",
    "length_of_array = len(array_1)\n",
    "\n",
    "array_1.reshape(length_of_array,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_array = \" \".join(str(i) for i in array_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "image_size = 48\n",
    "pixel_depth = 255.0\n",
    "\n",
    "def load_img(folder):\n",
    "    image_files = np.array(os.listdir(folder))\n",
    "    #i_files = image_files[:10]\n",
    "    dataset = np.ndarray(shape=(len(image_files),image_size,image_size),dtype = np.float32)\n",
    "    num_images = 0\n",
    "    for image in image_files:\n",
    "        image_file = os.path.join(folder,image)\n",
    "        image_data = cv2.imread(image_file,0)\n",
    "        image_data_resized = cv2.resize(image_data,(image_size,image_size))\n",
    "        #image_data_normalised = (image_data_resized.astype(float)-pixel_depth/2)/pixel_depth\n",
    "        if image_data_resized.shape != (48,48):\n",
    "            print(\"size of image is not as desired\")\n",
    "        dataset[num_images,:,:]=image_data_resized\n",
    "        num_images = num_images + 1\n",
    "        \n",
    "    dataset = dataset[0:num_images,:,:] \n",
    "    \n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "\n",
    "ck = load_img(\"CKimg_v1.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck_labels = pd.read_csv('ck+labels_v1.0.csv')\n",
    "\n",
    "ck_pd = pd.DataFrame({\n",
    "    \"emotions\":,\n",
    "    \"pixels\":})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "s = \" \".join(str(i) for i in [1,2,3,4,5])\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
